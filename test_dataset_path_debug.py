#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†è·¯å¾„è°ƒè¯•æµ‹è¯•è„šæœ¬

æµ‹è¯•æ•°æ®é›†é…ç½®æ–‡ä»¶çš„è·¯å¾„è§£æé€»è¾‘
"""

import os
import sys
import yaml
from pathlib import Path

def test_dataset_path_resolution():
    """æµ‹è¯•æ•°æ®é›†è·¯å¾„è§£æ"""
    print("ğŸ” æµ‹è¯•æ•°æ®é›†è·¯å¾„è§£æ")
    print("=" * 50)
    
    # æµ‹è¯•é…ç½®æ–‡ä»¶è·¯å¾„
    config_file = "datasets/training_dataset/data.yaml"
    
    print(f"ğŸ“ é…ç½®æ–‡ä»¶è·¯å¾„: {config_file}")
    print(f"ğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: {os.path.exists(config_file)}")
    
    if not os.path.exists(config_file):
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        return False
    
    # è¯»å–é…ç½®æ–‡ä»¶
    print("\nğŸ“‹ è¯»å–é…ç½®æ–‡ä»¶å†…å®¹:")
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    for key, value in config.items():
        print(f"   {key}: {value}")
    
    # è§£æè·¯å¾„
    print("\nğŸ”— è·¯å¾„è§£æè¿‡ç¨‹:")
    
    config_path = Path(config_file)
    config_dir = config_path.parent
    print(f"ğŸ“‚ é…ç½®æ–‡ä»¶ç›®å½•: {config_dir.absolute()}")
    
    # å¤„ç†pathå­—æ®µ
    if 'path' in config and config['path']:
        dataset_base_path = config['path']
        print(f"ğŸ—‚ï¸ æ•°æ®é›†pathå­—æ®µ: {dataset_base_path}")
        
        if not os.path.isabs(dataset_base_path):
            dataset_base_path = config_dir / dataset_base_path
            print(f"ğŸ”— è§£æåçš„ç»å¯¹è·¯å¾„: {dataset_base_path.absolute()}")
        
        dataset_base_path = Path(dataset_base_path)
    else:
        dataset_base_path = config_dir
        print("ğŸ“ ä½¿ç”¨é…ç½®æ–‡ä»¶ç›®å½•ä½œä¸ºåŸºç¡€è·¯å¾„")
    
    print(f"ğŸ“ æœ€ç»ˆåŸºç¡€è·¯å¾„: {dataset_base_path.absolute()}")
    
    # æ„å»ºè®­ç»ƒå’ŒéªŒè¯è·¯å¾„
    train_relative = config.get('train', '')
    val_relative = config.get('val', '')
    
    print(f"\nğŸš‚ è®­ç»ƒæ•°æ®ç›¸å¯¹è·¯å¾„: {train_relative}")
    print(f"âœ… éªŒè¯æ•°æ®ç›¸å¯¹è·¯å¾„: {val_relative}")
    
    train_path = dataset_base_path / train_relative
    val_path = dataset_base_path / val_relative
    
    print(f"ğŸš‚ è®­ç»ƒæ•°æ®ç»å¯¹è·¯å¾„: {train_path.absolute()}")
    print(f"âœ… éªŒè¯æ•°æ®ç»å¯¹è·¯å¾„: {val_path.absolute()}")
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    print(f"\nğŸ“Š è·¯å¾„å­˜åœ¨æ€§æ£€æŸ¥:")
    print(f"ğŸš‚ è®­ç»ƒè·¯å¾„å­˜åœ¨: {train_path.exists()}")
    print(f"âœ… éªŒè¯è·¯å¾„å­˜åœ¨: {val_path.exists()}")
    
    if train_path.exists():
        train_images = list(train_path.glob("*.jpg")) + list(train_path.glob("*.png")) + list(train_path.glob("*.jpeg"))
        print(f"ğŸ“Š è®­ç»ƒå›¾ç‰‡æ•°é‡: {len(train_images)}")
        if len(train_images) > 0:
            print(f"ğŸ“· ç¤ºä¾‹å›¾ç‰‡: {train_images[0].name}")
    
    if val_path.exists():
        val_images = list(val_path.glob("*.jpg")) + list(val_path.glob("*.png")) + list(val_path.glob("*.jpeg"))
        print(f"ğŸ“Š éªŒè¯å›¾ç‰‡æ•°é‡: {len(val_images)}")
        if len(val_images) > 0:
            print(f"ğŸ“· ç¤ºä¾‹å›¾ç‰‡: {val_images[0].name}")
    
    return True

def test_different_working_directories():
    """æµ‹è¯•ä¸åŒå·¥ä½œç›®å½•ä¸‹çš„è·¯å¾„è§£æ"""
    print("\nğŸ”„ æµ‹è¯•ä¸åŒå·¥ä½œç›®å½•")
    print("=" * 50)
    
    original_cwd = os.getcwd()
    print(f"ğŸ“‚ åŸå§‹å·¥ä½œç›®å½•: {original_cwd}")
    
    # æµ‹è¯•åœºæ™¯1ï¼šåœ¨é¡¹ç›®æ ¹ç›®å½•
    config_file = "datasets/training_dataset/data.yaml"
    if os.path.exists(config_file):
        print(f"\nâœ… åœºæ™¯1 - é¡¹ç›®æ ¹ç›®å½•: {original_cwd}")
        print(f"ğŸ“ é…ç½®æ–‡ä»¶: {config_file}")
        print(f"ğŸ”— ç»å¯¹è·¯å¾„: {os.path.abspath(config_file)}")
    
    # æµ‹è¯•åœºæ™¯2ï¼šåœ¨datasetsç›®å½•
    datasets_dir = os.path.join(original_cwd, "datasets")
    if os.path.exists(datasets_dir):
        try:
            os.chdir(datasets_dir)
            print(f"\nâœ… åœºæ™¯2 - datasetsç›®å½•: {os.getcwd()}")
            
            config_file2 = "training_dataset/data.yaml"
            if os.path.exists(config_file2):
                print(f"ğŸ“ é…ç½®æ–‡ä»¶: {config_file2}")
                print(f"ğŸ”— ç»å¯¹è·¯å¾„: {os.path.abspath(config_file2)}")
        finally:
            os.chdir(original_cwd)
    
    # æµ‹è¯•åœºæ™¯3ï¼šåœ¨training_datasetç›®å½•
    training_dir = os.path.join(original_cwd, "datasets", "training_dataset")
    if os.path.exists(training_dir):
        try:
            os.chdir(training_dir)
            print(f"\nâœ… åœºæ™¯3 - training_datasetç›®å½•: {os.getcwd()}")
            
            config_file3 = "data.yaml"
            if os.path.exists(config_file3):
                print(f"ğŸ“ é…ç½®æ–‡ä»¶: {config_file3}")
                print(f"ğŸ”— ç»å¯¹è·¯å¾„: {os.path.abspath(config_file3)}")
        finally:
            os.chdir(original_cwd)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª æ•°æ®é›†è·¯å¾„è°ƒè¯•æµ‹è¯•")
    print("=" * 60)
    
    try:
        # æµ‹è¯•åŸºæœ¬è·¯å¾„è§£æ
        success1 = test_dataset_path_resolution()
        
        # æµ‹è¯•ä¸åŒå·¥ä½œç›®å½•
        test_different_working_directories()
        
        print("\n" + "=" * 60)
        if success1:
            print("âœ… è·¯å¾„è§£ææµ‹è¯•å®Œæˆ")
            print("\nğŸ’¡ è°ƒè¯•å»ºè®®:")
            print("1. æ£€æŸ¥è®­ç»ƒæ—¥å¿—ä¸­çš„è·¯å¾„è§£æè¿‡ç¨‹")
            print("2. ç¡®è®¤æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸­çš„pathå­—æ®µæ˜¯å¦æ­£ç¡®")
            print("3. éªŒè¯è®­ç»ƒå’ŒéªŒè¯æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨")
            print("4. æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•ä¸­")
        else:
            print("âŒ è·¯å¾„è§£ææµ‹è¯•å¤±è´¥")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
