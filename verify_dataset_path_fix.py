#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
éªŒè¯æ•°æ®é›†è·¯å¾„ä¿®å¤æ˜¯å¦æˆåŠŸ
"""

import os
import yaml

def verify_path_fix():
    """éªŒè¯è·¯å¾„ä¿®å¤"""
    print("ğŸ” éªŒè¯æ•°æ®é›†è·¯å¾„ä¿®å¤")
    print("=" * 50)
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    config_file = "datasets/training_dataset/data.yaml"
    print(f"ğŸ“ é…ç½®æ–‡ä»¶: {config_file}")
    
    if not os.path.exists(config_file):
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # è¯»å–é…ç½®
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"ğŸ“„ é…ç½®å†…å®¹:")
    for key, value in config.items():
        print(f"   {key}: {value}")
    
    # æ¨¡æ‹ŸUIä¸­çš„è·¯å¾„è§£æé€»è¾‘
    print(f"\nğŸ”— UIè·¯å¾„è§£æé€»è¾‘:")
    config_dir = os.path.dirname(config_file)
    print(f"ğŸ“‚ é…ç½®æ–‡ä»¶ç›®å½•: {config_dir}")
    
    # å¤„ç†pathå­—æ®µ
    if 'path' in config and config['path']:
        dataset_base_path = config['path']
        print(f"ğŸ—‚ï¸ åŸå§‹pathå­—æ®µ: {dataset_base_path}")
        
        if not os.path.isabs(dataset_base_path):
            dataset_base_path = os.path.join(config_dir, dataset_base_path)
            print(f"ğŸ”— è§£æåçš„æ•°æ®é›†åŸºç¡€è·¯å¾„: {dataset_base_path}")
    else:
        dataset_base_path = config_dir
        print("ğŸ“ ä½¿ç”¨é…ç½®æ–‡ä»¶ç›®å½•ä½œä¸ºåŸºç¡€è·¯å¾„")
    
    # æ„å»ºè®­ç»ƒå’ŒéªŒè¯è·¯å¾„
    train_relative = config.get('train', '')
    val_relative = config.get('val', '')
    
    train_path = os.path.join(dataset_base_path, train_relative)
    val_path = os.path.join(dataset_base_path, val_relative)
    
    print(f"ğŸš‚ è®­ç»ƒè·¯å¾„: {train_relative} -> {train_path}")
    print(f"âœ… éªŒè¯è·¯å¾„: {val_relative} -> {val_path}")
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    print(f"\nğŸ“Š è·¯å¾„å­˜åœ¨æ€§æ£€æŸ¥:")
    print(f"ğŸš‚ è®­ç»ƒè·¯å¾„å­˜åœ¨: {os.path.exists(train_path)}")
    print(f"âœ… éªŒè¯è·¯å¾„å­˜åœ¨: {os.path.exists(val_path)}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤è·¯å¾„é—®é¢˜
    print(f"\nğŸ” æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®:")
    expected_train = "datasets/training_dataset/images/train"
    expected_val = "datasets/training_dataset/images/val"
    
    # æ ‡å‡†åŒ–è·¯å¾„è¿›è¡Œæ¯”è¾ƒ
    train_normalized = os.path.normpath(train_path)
    val_normalized = os.path.normpath(val_path)
    expected_train_normalized = os.path.normpath(expected_train)
    expected_val_normalized = os.path.normpath(expected_val)
    
    print(f"ğŸš‚ è®­ç»ƒè·¯å¾„æ­£ç¡®: {train_normalized == expected_train_normalized}")
    print(f"âœ… éªŒè¯è·¯å¾„æ­£ç¡®: {val_normalized == expected_val_normalized}")
    
    if train_normalized == expected_train_normalized and val_normalized == expected_val_normalized:
        print(f"\nğŸ‰ è·¯å¾„ä¿®å¤æˆåŠŸï¼")
        print(f"âœ… è®­ç»ƒè·¯å¾„: {train_normalized}")
        print(f"âœ… éªŒè¯è·¯å¾„: {val_normalized}")
        return True
    else:
        print(f"\nâŒ è·¯å¾„ä»æœ‰é—®é¢˜:")
        print(f"   æœŸæœ›è®­ç»ƒè·¯å¾„: {expected_train_normalized}")
        print(f"   å®é™…è®­ç»ƒè·¯å¾„: {train_normalized}")
        print(f"   æœŸæœ›éªŒè¯è·¯å¾„: {expected_val_normalized}")
        print(f"   å®é™…éªŒè¯è·¯å¾„: {val_normalized}")
        return False

if __name__ == "__main__":
    verify_path_fix()
