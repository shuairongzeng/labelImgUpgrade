#!/usr/bin/env python
# -*- coding: utf8 -*-
import os
import shutil
import random
import yaml
from xml.etree import ElementTree
from libs.constants import DEFAULT_ENCODING
from libs.class_manager import ClassConfigManager


class PascalToYOLOConverter:
    """Pascal VOCåˆ°YOLOæ ¼å¼çš„è½¬æ¢å™¨ - æ”¯æŒå›ºå®šç±»åˆ«é¡ºåº"""

    def __init__(self, source_dir, target_dir, dataset_name="dataset", train_ratio=0.8,
                 use_class_config=True, class_config_dir="configs"):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨

        Args:
            source_dir: æºç›®å½•ï¼ŒåŒ…å«å›¾ç‰‡å’ŒXMLæ ‡æ³¨æ–‡ä»¶
            target_dir: ç›®æ ‡ç›®å½•ï¼Œå°†åˆ›å»ºYOLOæ ¼å¼çš„æ•°æ®é›†
            dataset_name: æ•°æ®é›†åç§°
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹ï¼Œé»˜è®¤0.8
            use_class_config: æ˜¯å¦ä½¿ç”¨ç±»åˆ«é…ç½®ç®¡ç†å™¨ï¼Œé»˜è®¤True
            class_config_dir: ç±»åˆ«é…ç½®æ–‡ä»¶ç›®å½•ï¼Œé»˜è®¤"configs"
        """
        self.source_dir = source_dir
        self.target_dir = target_dir
        self.dataset_name = dataset_name
        self.train_ratio = train_ratio
        self.use_class_config = use_class_config

        # æ•°æ®é›†è·¯å¾„
        self.dataset_path = os.path.join(target_dir, dataset_name)
        self.images_dir = os.path.join(self.dataset_path, "images")
        self.labels_dir = os.path.join(self.dataset_path, "labels")
        self.train_images_dir = os.path.join(self.images_dir, "train")
        self.val_images_dir = os.path.join(self.images_dir, "val")
        self.train_labels_dir = os.path.join(self.labels_dir, "train")
        self.val_labels_dir = os.path.join(self.labels_dir, "val")

        # ç±»åˆ«ç®¡ç†
        if self.use_class_config:
            self.class_manager = ClassConfigManager(class_config_dir)
            self.class_manager.load_class_config()
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å›ºå®šç±»åˆ«é¡ºåº
            self.classes = self.class_manager.get_class_list()
            self.class_to_id = self.class_manager.get_class_to_id_mapping()
            print(f"ğŸ“‹ ä½¿ç”¨å›ºå®šç±»åˆ«é…ç½®: {len(self.classes)} ä¸ªç±»åˆ«")
            if self.classes:
                print(f"ğŸ·ï¸ ç±»åˆ«é¡ºåº: {self.classes}")
        else:
            # ä¼ ç»Ÿçš„åŠ¨æ€ç±»åˆ«æ·»åŠ æ–¹å¼ï¼ˆä¸æ¨èï¼‰
            self.classes = []
            self.class_to_id = {}
            self.class_manager = None
            print("âš ï¸ ä½¿ç”¨åŠ¨æ€ç±»åˆ«æ·»åŠ æ¨¡å¼ï¼ˆå¯èƒ½å¯¼è‡´é¡ºåºä¸ä¸€è‡´ï¼‰")

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_files = 0
        self.processed_files = 0
        self.train_count = 0
        self.val_count = 0
        self.unknown_classes = set()  # è®°å½•æœªçŸ¥ç±»åˆ«

    def create_directories(self, clean_existing=False, backup_existing=False):
        """
        åˆ›å»ºYOLOæ•°æ®é›†ç›®å½•ç»“æ„

        Args:
            clean_existing: æ˜¯å¦æ¸…ç©ºç°æœ‰ç›®å½•
            backup_existing: æ˜¯å¦å¤‡ä»½ç°æœ‰ç›®å½•
        """
        directories = [
            self.dataset_path,
            self.images_dir,
            self.labels_dir,
            self.train_images_dir,
            self.val_images_dir,
            self.train_labels_dir,
            self.val_labels_dir
        ]

        # å¦‚æœéœ€è¦å¤‡ä»½ç°æœ‰æ•°æ®
        if backup_existing and os.path.exists(self.dataset_path):
            self._backup_existing_dataset()

        # å¦‚æœéœ€è¦æ¸…ç©ºç°æœ‰ç›®å½•
        if clean_existing:
            self._clean_existing_directories(directories)

        # åˆ›å»ºç›®å½•ç»“æ„
        for directory in directories:
            os.makedirs(directory, exist_ok=True)

    def _backup_existing_dataset(self):
        """å¤‡ä»½ç°æœ‰æ•°æ®é›†"""
        try:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = f"{self.dataset_path}_backup_{timestamp}"

            print(f"ğŸ“‹ å¤‡ä»½ç°æœ‰æ•°æ®é›†åˆ°: {backup_path}")
            shutil.copytree(self.dataset_path, backup_path)

            # è®°å½•å¤‡ä»½è·¯å¾„ï¼Œç”¨äºå¯èƒ½çš„æ¢å¤
            self.backup_path = backup_path
            print(f"âœ… æ•°æ®é›†å¤‡ä»½å®Œæˆ: {backup_path}")

        except Exception as e:
            print(f"âš ï¸ å¤‡ä»½æ•°æ®é›†å¤±è´¥: {e}")
            self.backup_path = None

    def _clean_existing_directories(self, directories):
        """æ¸…ç©ºç°æœ‰ç›®å½•"""
        try:
            cleaned_count = 0
            for directory in directories:
                if os.path.exists(directory):
                    # ç»Ÿè®¡è¦åˆ é™¤çš„æ–‡ä»¶æ•°é‡
                    file_count = sum([len(files)
                                     for r, d, files in os.walk(directory)])
                    if file_count > 0:
                        print(f"ğŸ—‘ï¸ æ¸…ç©ºç›®å½•: {directory} ({file_count} ä¸ªæ–‡ä»¶)")
                        shutil.rmtree(directory)
                        cleaned_count += file_count

            if cleaned_count > 0:
                print(f"âœ… å·²æ¸…ç©º {cleaned_count} ä¸ªç°æœ‰æ–‡ä»¶")
            else:
                print("â„¹ï¸ ç›®æ ‡ç›®å½•ä¸ºç©ºï¼Œæ— éœ€æ¸…ç©º")

        except Exception as e:
            print(f"âŒ æ¸…ç©ºç›®å½•å¤±è´¥: {e}")
            raise

    def get_existing_files_info(self):
        """è·å–ç°æœ‰æ–‡ä»¶ä¿¡æ¯ï¼Œç”¨äºç”¨æˆ·ç¡®è®¤"""
        try:
            info = {
                'dataset_exists': os.path.exists(self.dataset_path),
                'total_files': 0,
                'train_images': 0,
                'val_images': 0,
                'train_labels': 0,
                'val_labels': 0
            }

            if info['dataset_exists']:
                # ç»Ÿè®¡å„ç±»æ–‡ä»¶æ•°é‡
                if os.path.exists(self.train_images_dir):
                    info['train_images'] = len([f for f in os.listdir(self.train_images_dir)
                                               if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])

                if os.path.exists(self.val_images_dir):
                    info['val_images'] = len([f for f in os.listdir(self.val_images_dir)
                                             if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])

                if os.path.exists(self.train_labels_dir):
                    info['train_labels'] = len([f for f in os.listdir(self.train_labels_dir)
                                               if f.endswith('.txt')])

                if os.path.exists(self.val_labels_dir):
                    info['val_labels'] = len([f for f in os.listdir(self.val_labels_dir)
                                             if f.endswith('.txt')])

                info['total_files'] = info['train_images'] + \
                    info['val_images'] + \
                    info['train_labels'] + info['val_labels']

            return info

        except Exception as e:
            print(f"âš ï¸ è·å–ç°æœ‰æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
            return {'dataset_exists': False, 'total_files': 0}

    def verify_conversion_integrity(self, source_files):
        """éªŒè¯è½¬æ¢åçš„æ•°æ®å®Œæ•´æ€§"""
        try:
            print("ğŸ” éªŒè¯è½¬æ¢æ•°æ®å®Œæ•´æ€§...")

            # ç»Ÿè®¡è½¬æ¢åçš„æ–‡ä»¶
            train_images = len([f for f in os.listdir(self.train_images_dir)
                               if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]) if os.path.exists(self.train_images_dir) else 0
            val_images = len([f for f in os.listdir(self.val_images_dir)
                             if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]) if os.path.exists(self.val_images_dir) else 0
            train_labels = len([f for f in os.listdir(self.train_labels_dir)
                               if f.endswith('.txt')]) if os.path.exists(self.train_labels_dir) else 0
            val_labels = len([f for f in os.listdir(self.val_labels_dir)
                             if f.endswith('.txt')]) if os.path.exists(self.val_labels_dir) else 0

            total_converted = train_images + val_images
            total_source = len(source_files)

            # éªŒè¯æ–‡ä»¶æ•°é‡
            integrity_report = {
                'source_files': total_source,
                'converted_images': total_converted,
                'train_images': train_images,
                'val_images': val_images,
                'train_labels': train_labels,
                'val_labels': val_labels,
                'images_match_labels': train_images == train_labels and val_images == val_labels,
                'all_files_converted': total_converted == total_source,
                'integrity_passed': False
            }

            # æ£€æŸ¥å®Œæ•´æ€§
            if integrity_report['images_match_labels'] and integrity_report['all_files_converted']:
                integrity_report['integrity_passed'] = True
                print("âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
                print(f"   æºæ–‡ä»¶: {total_source} ä¸ª")
                print(f"   è½¬æ¢å›¾ç‰‡: {total_converted} ä¸ª")
                print(f"   è®­ç»ƒé›†: {train_images} å›¾ç‰‡, {train_labels} æ ‡ç­¾")
                print(f"   éªŒè¯é›†: {val_images} å›¾ç‰‡, {val_labels} æ ‡ç­¾")
            else:
                print("âš ï¸ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥")
                if not integrity_report['all_files_converted']:
                    print(
                        f"   æ–‡ä»¶æ•°é‡ä¸åŒ¹é…: æºæ–‡ä»¶ {total_source} ä¸ª, è½¬æ¢ {total_converted} ä¸ª")
                if not integrity_report['images_match_labels']:
                    print(
                        f"   å›¾ç‰‡æ ‡ç­¾ä¸åŒ¹é…: è®­ç»ƒé›† {train_images}:{train_labels}, éªŒè¯é›† {val_images}:{val_labels}")

            return integrity_report

        except Exception as e:
            print(f"âŒ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
            return {'integrity_passed': False, 'error': str(e)}

    def scan_annotations(self):
        """æ‰«ææºç›®å½•ä¸­çš„XMLæ ‡æ³¨æ–‡ä»¶"""
        xml_files = []
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']

        for file in os.listdir(self.source_dir):
            if file.lower().endswith('.xml'):
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
                base_name = os.path.splitext(file)[0]
                image_file = None

                for ext in image_extensions:
                    potential_image = os.path.join(
                        self.source_dir, base_name + ext)
                    if os.path.exists(potential_image):
                        image_file = base_name + ext
                        break

                if image_file:
                    xml_files.append((file, image_file))

        return xml_files

    def parse_xml_annotation(self, xml_path):
        """è§£æPascal VOC XMLæ ‡æ³¨æ–‡ä»¶"""
        try:
            tree = ElementTree.parse(xml_path)
            root = tree.getroot()

            # è·å–å›¾ç‰‡å°ºå¯¸
            size = root.find('size')
            if size is None:
                return None, None, None

            width = int(size.find('width').text)
            height = int(size.find('height').text)

            # è§£ææ‰€æœ‰å¯¹è±¡
            objects = []
            for obj in root.findall('object'):
                name = obj.find('name').text

                # å¤„ç†ç±»åˆ«æ˜ å°„
                if self.use_class_config:
                    # ä½¿ç”¨å›ºå®šç±»åˆ«é…ç½®
                    if name not in self.class_to_id:
                        # å°è¯•è‡ªåŠ¨æ·»åŠ æ–°ç±»åˆ«åˆ°é…ç½®
                        if self._auto_add_unknown_class(name):
                            class_id = self.class_to_id[name]
                            print(f"âœ… è‡ªåŠ¨æ·»åŠ æ–°ç±»åˆ«: {name} (ID: {class_id})")
                        else:
                            # è®°å½•æœªçŸ¥ç±»åˆ«å¹¶è·³è¿‡
                            self.unknown_classes.add(name)
                            print(f"âš ï¸ å‘ç°æœªçŸ¥ç±»åˆ«: {name} (å°†è·³è¿‡æ­¤å¯¹è±¡)")
                            continue
                    else:
                        class_id = self.class_to_id[name]
                else:
                    # ä¼ ç»Ÿçš„åŠ¨æ€æ·»åŠ æ–¹å¼
                    if name not in self.classes:
                        self.classes.append(name)
                        self.class_to_id[name] = len(self.classes) - 1
                    class_id = self.class_to_id[name]

                # è·å–è¾¹ç•Œæ¡†
                bbox = obj.find('bndbox')
                if bbox is None:
                    continue

                xmin = float(bbox.find('xmin').text)
                ymin = float(bbox.find('ymin').text)
                xmax = float(bbox.find('xmax').text)
                ymax = float(bbox.find('ymax').text)

                # è½¬æ¢ä¸ºYOLOæ ¼å¼ (ä¸­å¿ƒç‚¹åæ ‡å’Œç›¸å¯¹å°ºå¯¸)
                x_center = (xmin + xmax) / 2.0 / width
                y_center = (ymin + ymax) / 2.0 / height
                bbox_width = (xmax - xmin) / width
                bbox_height = (ymax - ymin) / height

                objects.append(
                    (class_id, x_center, y_center, bbox_width, bbox_height))

            return width, height, objects

        except Exception as e:
            print(f"Error parsing XML file {xml_path}: {e}")
            return None, None, None

    def write_yolo_annotation(self, objects, output_path):
        """å†™å…¥YOLOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶"""
        try:
            with open(output_path, 'w', encoding=DEFAULT_ENCODING) as f:
                for obj in objects:
                    class_id, x_center, y_center, width, height = obj
                    f.write(
                        f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
            return True
        except Exception as e:
            print(f"Error writing YOLO annotation to {output_path}: {e}")
            return False

    def copy_image(self, source_image_path, target_image_path):
        """å¤åˆ¶å›¾ç‰‡æ–‡ä»¶"""
        try:
            shutil.copy2(source_image_path, target_image_path)
            return True
        except Exception as e:
            print(
                f"Error copying image from {source_image_path} to {target_image_path}: {e}")
            return False

    def generate_classes_file(self):
        """ç”Ÿæˆclasses.txtæ–‡ä»¶"""
        classes_file = os.path.join(self.dataset_path, "classes.txt")
        try:
            with open(classes_file, 'w', encoding=DEFAULT_ENCODING) as f:
                for class_name in self.classes:
                    f.write(f"{class_name}\n")
            return True
        except Exception as e:
            print(f"Error generating classes file: {e}")
            return False

    def generate_yaml_config(self):
        """ç”ŸæˆYOLOè®­ç»ƒé…ç½®æ–‡ä»¶"""
        yaml_file = os.path.join(self.dataset_path, "data.yaml")

        # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿YOLOè®­ç»ƒå™¨èƒ½æ­£ç¡®æ‰¾åˆ°æ•°æ®
        dataset_abs_path = os.path.abspath(self.dataset_path)

        config = {
            'path': dataset_abs_path,  # ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿YOLOè®­ç»ƒå™¨èƒ½æ­£ç¡®æ‰¾åˆ°æ•°æ®
            'train': "images/train",   # ç›¸å¯¹äºpathå­—æ®µçš„è·¯å¾„
            'val': "images/val",       # ç›¸å¯¹äºpathå­—æ®µçš„è·¯å¾„
            'test': None,
            'names': {i: name for i, name in enumerate(self.classes)}
        }

        try:
            with open(yaml_file, 'w', encoding=DEFAULT_ENCODING) as f:
                yaml.dump(config, f, default_flow_style=False,
                          allow_unicode=True)
            return True
        except Exception as e:
            print(f"Error generating YAML config: {e}")
            return False

    def convert(self, progress_callback=None, clean_existing=False, backup_existing=False):
        """
        æ‰§è¡Œè½¬æ¢è¿‡ç¨‹

        Args:
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (current, total, message) å‚æ•°
            clean_existing: æ˜¯å¦æ¸…ç©ºç°æœ‰ç›®å½•
            backup_existing: æ˜¯å¦å¤‡ä»½ç°æœ‰ç›®å½•
        """
        try:
            # åˆ›å»ºç›®å½•ç»“æ„
            self.create_directories(
                clean_existing=clean_existing, backup_existing=backup_existing)

            # å¦‚æœä½¿ç”¨ç±»åˆ«é…ç½®ä½†é…ç½®ä¸ºç©ºï¼Œå…ˆæ‰«ææ‰€æœ‰ç±»åˆ«
            if self.use_class_config and not self.classes:
                if progress_callback:
                    progress_callback(0, 100, "æ‰«ææ•°æ®é›†ç±»åˆ«...")
                self._scan_and_setup_classes()

            # æ‰«ææ ‡æ³¨æ–‡ä»¶
            if progress_callback:
                progress_callback(5, 100, "æ‰«ææ ‡æ³¨æ–‡ä»¶...")

            xml_files = self.scan_annotations()
            if not xml_files:
                raise Exception("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ ‡æ³¨æ–‡ä»¶")

            self.total_files = len(xml_files)

            # éšæœºåˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
            random.shuffle(xml_files)
            split_index = int(len(xml_files) * self.train_ratio)
            train_files = xml_files[:split_index]
            val_files = xml_files[split_index:]

            # å¤„ç†è®­ç»ƒé›†
            if progress_callback:
                progress_callback(
                    10, 100, f"å¤„ç†è®­ç»ƒé›†æ–‡ä»¶ ({len(train_files)} ä¸ª)...")

            for i, (xml_file, image_file) in enumerate(train_files):
                self._process_file(xml_file, image_file, is_train=True)
                self.train_count += 1
                if progress_callback:
                    progress = 10 + (i + 1) / len(train_files) * 40
                    progress_callback(int(progress), 100,
                                      f"å¤„ç†è®­ç»ƒé›†: {i+1}/{len(train_files)}")

            # å¤„ç†éªŒè¯é›†
            if progress_callback:
                progress_callback(50, 100, f"å¤„ç†éªŒè¯é›†æ–‡ä»¶ ({len(val_files)} ä¸ª)...")

            for i, (xml_file, image_file) in enumerate(val_files):
                self._process_file(xml_file, image_file, is_train=False)
                self.val_count += 1
                if progress_callback:
                    progress = 50 + (i + 1) / len(val_files) * 40
                    progress_callback(int(progress), 100,
                                      f"å¤„ç†éªŒè¯é›†: {i+1}/{len(val_files)}")

            # ç”Ÿæˆé…ç½®æ–‡ä»¶
            if progress_callback:
                progress_callback(90, 100, "ç”Ÿæˆé…ç½®æ–‡ä»¶...")

            self.generate_classes_file()
            self.generate_yaml_config()

            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            if progress_callback:
                progress_callback(95, 100, "éªŒè¯æ•°æ®å®Œæ•´æ€§...")

            integrity_report = self.verify_conversion_integrity(xml_files)
            if not integrity_report.get('integrity_passed', False):
                warning_msg = "âš ï¸ æ•°æ®å®Œæ•´æ€§éªŒè¯æœªé€šè¿‡ï¼Œä½†è½¬æ¢å·²å®Œæˆ"
                print(warning_msg)

            if progress_callback:
                progress_callback(100, 100, "è½¬æ¢å®Œæˆ!")

            # ç”Ÿæˆè½¬æ¢æŠ¥å‘Š
            report = self._generate_conversion_report()

            # æ·»åŠ å®Œæ•´æ€§ä¿¡æ¯åˆ°æŠ¥å‘Š
            if integrity_report.get('integrity_passed', False):
                report += "\n\nâœ… æ•°æ®å®Œæ•´æ€§éªŒè¯: é€šè¿‡"
            else:
                report += "\n\nâš ï¸ æ•°æ®å®Œæ•´æ€§éªŒè¯: æœªé€šè¿‡"
                if 'error' in integrity_report:
                    report += f"\n   é”™è¯¯: {integrity_report['error']}"

            return True, report

        except Exception as e:
            return False, str(e)

    def _process_file(self, xml_file, image_file, is_train=True):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        xml_path = os.path.join(self.source_dir, xml_file)
        image_path = os.path.join(self.source_dir, image_file)

        # è§£æXMLæ ‡æ³¨
        width, height, objects = self.parse_xml_annotation(xml_path)
        if objects is None:
            return False

        # ç¡®å®šç›®æ ‡ç›®å½•
        if is_train:
            target_images_dir = self.train_images_dir
            target_labels_dir = self.train_labels_dir
        else:
            target_images_dir = self.val_images_dir
            target_labels_dir = self.val_labels_dir

        # å¤åˆ¶å›¾ç‰‡
        base_name = os.path.splitext(image_file)[0]
        target_image_path = os.path.join(target_images_dir, image_file)
        if not self.copy_image(image_path, target_image_path):
            return False

        # å†™å…¥YOLOæ ‡æ³¨
        target_label_path = os.path.join(target_labels_dir, base_name + ".txt")
        if not self.write_yolo_annotation(objects, target_label_path):
            return False

        self.processed_files += 1
        return True

    def _scan_and_setup_classes(self):
        """æ‰«ææ•°æ®é›†ä¸­çš„æ‰€æœ‰ç±»åˆ«å¹¶è®¾ç½®ç±»åˆ«é…ç½®"""
        try:
            print("ğŸ” æ‰«ææ•°æ®é›†ä¸­çš„ç±»åˆ«...")
            found_classes = set()

            # æ‰«ææ‰€æœ‰XMLæ–‡ä»¶è·å–ç±»åˆ«
            xml_files = self.scan_annotations()
            for xml_file in xml_files:
                xml_path = os.path.join(self.source_dir, xml_file)
                try:
                    tree = ElementTree.parse(xml_path)
                    root = tree.getroot()

                    for obj in root.findall('object'):
                        name = obj.find('name').text
                        if name:
                            found_classes.add(name)

                except Exception as e:
                    print(f"âš ï¸ è§£æXMLæ–‡ä»¶å¤±è´¥ {xml_file}: {e}")

            found_classes = sorted(list(found_classes))  # æŒ‰å­—æ¯é¡ºåºæ’åº
            print(f"ğŸ“‹ å‘ç°ç±»åˆ«: {found_classes}")

            if found_classes:
                # æ›´æ–°ç±»åˆ«é…ç½®
                self.class_manager.class_config['classes'] = found_classes
                for idx, class_name in enumerate(found_classes):
                    from datetime import datetime
                    self.class_manager.class_config['class_metadata'][class_name] = {
                        'description': f"ä»æ•°æ®é›†è‡ªåŠ¨å‘ç°çš„ç±»åˆ«",
                        'added_at': datetime.now().isoformat(),
                        'usage_count': 0,
                        'auto_discovered': True
                    }

                # ä¿å­˜é…ç½®
                self.class_manager.save_class_config()

                # æ›´æ–°å½“å‰å®ä¾‹çš„ç±»åˆ«ä¿¡æ¯
                self.classes = found_classes
                self.class_to_id = {name: idx for idx,
                                    name in enumerate(found_classes)}

                print(f"âœ… è‡ªåŠ¨é…ç½®äº† {len(found_classes)} ä¸ªç±»åˆ«")
            else:
                print("âš ï¸ æœªå‘ç°ä»»ä½•ç±»åˆ«")

        except Exception as e:
            print(f"âŒ æ‰«æç±»åˆ«å¤±è´¥: {e}")

    def _auto_add_unknown_class(self, class_name: str) -> bool:
        """
        è‡ªåŠ¨æ·»åŠ æœªçŸ¥ç±»åˆ«åˆ°é…ç½®ä¸­

        Args:
            class_name: ç±»åˆ«åç§°

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        try:
            if not self.class_manager:
                return False

            print(f"ğŸ”„ å°è¯•è‡ªåŠ¨æ·»åŠ æœªçŸ¥ç±»åˆ«: {class_name}")

            # æ·»åŠ ç±»åˆ«åˆ°é…ç½®ç®¡ç†å™¨
            success = self.class_manager.add_class(
                class_name,
                description=f"è½¬æ¢è¿‡ç¨‹ä¸­è‡ªåŠ¨å‘ç°çš„ç±»åˆ«"
            )

            if success:
                # é‡æ–°åŠ è½½ç±»åˆ«é…ç½®
                self.classes = self.class_manager.get_class_list()
                self.class_to_id = self.class_manager.get_class_to_id_mapping()

                # ä¿å­˜é…ç½®
                self.class_manager.save_class_config()

                print(f"âœ… æˆåŠŸæ·»åŠ ç±»åˆ«: {class_name}")
                print(f"ğŸ“‹ æ›´æ–°åçš„ç±»åˆ«åˆ—è¡¨: {self.classes}")

                return True
            else:
                print(f"âŒ æ·»åŠ ç±»åˆ«å¤±è´¥: {class_name}")
                return False

        except Exception as e:
            print(f"âŒ è‡ªåŠ¨æ·»åŠ ç±»åˆ«æ—¶å‡ºé”™: {e}")
            return False

    def _generate_conversion_report(self) -> str:
        """ç”Ÿæˆè½¬æ¢æŠ¥å‘Š"""
        try:
            report_lines = [
                f"âœ… è½¬æ¢å®Œæˆï¼",
                f"ğŸ“Š æ–‡ä»¶ç»Ÿè®¡:",
                f"  - æ€»æ–‡ä»¶æ•°: {self.total_files}",
                f"  - è®­ç»ƒé›†: {self.train_count} ä¸ª",
                f"  - éªŒè¯é›†: {self.val_count} ä¸ª",
                f"ğŸ·ï¸ ç±»åˆ«ä¿¡æ¯:",
                f"  - ç±»åˆ«æ•°é‡: {len(self.classes)}",
                f"  - ç±»åˆ«åˆ—è¡¨: {self.classes}"
            ]

            if self.use_class_config:
                report_lines.append(f"ğŸ“‹ ä½¿ç”¨å›ºå®šç±»åˆ«é…ç½®: âœ…")
                if self.unknown_classes:
                    report_lines.extend([
                        f"âš ï¸ å‘ç°æœªçŸ¥ç±»åˆ« (å·²è·³è¿‡):",
                        f"  - {sorted(list(self.unknown_classes))}"
                    ])
            else:
                report_lines.append(f"âš ï¸ ä½¿ç”¨åŠ¨æ€ç±»åˆ«æ·»åŠ  (å¯èƒ½å¯¼è‡´é¡ºåºä¸ä¸€è‡´)")

            return "\n".join(report_lines)

        except Exception as e:
            return f"è½¬æ¢å®Œæˆï¼Œä½†ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}"

    def get_class_statistics(self) -> dict:
        """è·å–ç±»åˆ«ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_classes': len(self.classes),
            'classes': self.classes.copy(),
            'class_to_id': self.class_to_id.copy(),
            'unknown_classes': sorted(list(self.unknown_classes)),
            'use_class_config': self.use_class_config,
            'config_file': self.class_manager.class_config_file if self.class_manager else None
        }
