#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•AIåŠ©æ‰‹é¢æ¿çš„GPU/CPUè®­ç»ƒåŠŸèƒ½

æµ‹è¯•å†…å®¹:
1. ç¡¬ä»¶ä¿¡æ¯æ£€æµ‹
2. GPU/CPUè®¾å¤‡é€‰æ‹©
3. PyTorchç¯å¢ƒæ£€æŸ¥
4. è®­ç»ƒç¯å¢ƒé…ç½®
"""

import sys
import os
import unittest
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from PyQt5.QtWidgets import QApplication, QMainWindow
    from PyQt5.QtCore import Qt
    from PyQt5.QtTest import QTest
    
    from libs.ai_assistant_panel import AIAssistantPanel
    
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€æœ‰å¿…éœ€æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)


class TestGPUCPUTraining(unittest.TestCase):
    """æµ‹è¯•GPU/CPUè®­ç»ƒåŠŸèƒ½"""
    
    @classmethod
    def setUpClass(cls):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        if not QApplication.instance():
            cls.app = QApplication(sys.argv)
        else:
            cls.app = QApplication.instance()
    
    def setUp(self):
        """æ¯ä¸ªæµ‹è¯•å‰çš„è®¾ç½®"""
        self.main_window = QMainWindow()
        self.ai_panel = AIAssistantPanel(self.main_window)
        
    def tearDown(self):
        """æ¯ä¸ªæµ‹è¯•åçš„æ¸…ç†"""
        if hasattr(self, 'ai_panel'):
            self.ai_panel.close()
        if hasattr(self, 'main_window'):
            self.main_window.close()
    
    def test_hardware_info_initialization(self):
        """æµ‹è¯•ç¡¬ä»¶ä¿¡æ¯åˆå§‹åŒ–"""
        print("\n=== æµ‹è¯•ç¡¬ä»¶ä¿¡æ¯åˆå§‹åŒ– ===")
        
        # æ£€æŸ¥ç¡¬ä»¶ä¿¡æ¯ç»“æ„æ˜¯å¦å­˜åœ¨
        self.assertTrue(hasattr(self.ai_panel, 'hardware_info'))
        self.assertTrue(hasattr(self.ai_panel, 'device_status'))
        
        # æ£€æŸ¥ç¡¬ä»¶ä¿¡æ¯å­—æ®µ
        required_fields = ['gpu_available', 'gpu_name', 'cuda_version', 'pytorch_version', 'recommended_device']
        for field in required_fields:
            self.assertIn(field, self.ai_panel.hardware_info)
        
        print("âœ… ç¡¬ä»¶ä¿¡æ¯åˆå§‹åŒ–æˆåŠŸ")
    
    @patch('torch.cuda.is_available')
    @patch('torch.cuda.get_device_name')
    @patch('torch.version.cuda')
    @patch('torch.__version__')
    def test_gpu_detection(self, mock_torch_version, mock_cuda_version, mock_gpu_name, mock_cuda_available):
        """æµ‹è¯•GPUæ£€æµ‹åŠŸèƒ½"""
        print("\n=== æµ‹è¯•GPUæ£€æµ‹åŠŸèƒ½ ===")
        
        # æ¨¡æ‹Ÿæœ‰GPUçš„æƒ…å†µ
        mock_cuda_available.return_value = True
        mock_gpu_name.return_value = "NVIDIA GeForce RTX 3080"
        mock_cuda_version = "11.8"
        mock_torch_version = "2.0.0"
        
        # æ‰§è¡Œç¡¬ä»¶æ£€æµ‹
        self.ai_panel.detect_hardware_info()
        
        # éªŒè¯GPUæ£€æµ‹ç»“æœ
        self.assertTrue(self.ai_panel.hardware_info['gpu_available'])
        self.assertEqual(self.ai_panel.hardware_info['recommended_device'], 'cuda')
        
        print("âœ… GPUæ£€æµ‹åŠŸèƒ½æ­£å¸¸")
    
    @patch('torch.cuda.is_available')
    def test_cpu_fallback(self, mock_cuda_available):
        """æµ‹è¯•CPUå›é€€åŠŸèƒ½"""
        print("\n=== æµ‹è¯•CPUå›é€€åŠŸèƒ½ ===")
        
        # æ¨¡æ‹Ÿæ²¡æœ‰GPUçš„æƒ…å†µ
        mock_cuda_available.return_value = False
        
        # æ‰§è¡Œç¡¬ä»¶æ£€æµ‹
        self.ai_panel.detect_hardware_info()
        
        # éªŒè¯CPUå›é€€
        self.assertFalse(self.ai_panel.hardware_info['gpu_available'])
        self.assertEqual(self.ai_panel.hardware_info['recommended_device'], 'cpu')
        
        print("âœ… CPUå›é€€åŠŸèƒ½æ­£å¸¸")
    
    def test_pytorch_install_command_generation(self):
        """æµ‹è¯•PyTorchå®‰è£…å‘½ä»¤ç”Ÿæˆ"""
        print("\n=== æµ‹è¯•PyTorchå®‰è£…å‘½ä»¤ç”Ÿæˆ ===")
        
        # æµ‹è¯•GPUç‰ˆæœ¬å‘½ä»¤
        self.ai_panel.hardware_info['gpu_available'] = True
        self.ai_panel.hardware_info['cuda_version'] = '11.8'
        
        gpu_command = self.ai_panel.get_pytorch_install_command()
        self.assertIn("cu118", gpu_command)
        
        print(f"GPUå‘½ä»¤: {gpu_command}")
        
        # æµ‹è¯•CPUç‰ˆæœ¬å‘½ä»¤
        self.ai_panel.hardware_info['gpu_available'] = False
        self.ai_panel.hardware_info['nvidia_driver'] = 'Not Found'
        
        cpu_command = self.ai_panel.get_pytorch_install_command()
        self.assertIn("torch", cpu_command)
        
        print(f"CPUå‘½ä»¤: {cpu_command}")
        print("âœ… PyTorchå®‰è£…å‘½ä»¤ç”Ÿæˆæ­£å¸¸")
    
    def test_training_environment_methods(self):
        """æµ‹è¯•è®­ç»ƒç¯å¢ƒç›¸å…³æ–¹æ³•"""
        print("\n=== æµ‹è¯•è®­ç»ƒç¯å¢ƒç›¸å…³æ–¹æ³• ===")
        
        # æ£€æŸ¥æ–¹æ³•æ˜¯å¦å­˜åœ¨
        self.assertTrue(hasattr(self.ai_panel, 'detect_hardware_info'))
        self.assertTrue(hasattr(self.ai_panel, 'check_training_environment'))
        self.assertTrue(hasattr(self.ai_panel, 'show_pytorch_install_dialog'))
        self.assertTrue(hasattr(self.ai_panel, 'get_pytorch_install_command'))
        
        print("âœ… è®­ç»ƒç¯å¢ƒç›¸å…³æ–¹æ³•å­˜åœ¨")


def run_hardware_detection_test():
    """è¿è¡Œç¡¬ä»¶æ£€æµ‹æµ‹è¯•"""
    print("\nğŸ” ç¡¬ä»¶æ£€æµ‹æµ‹è¯•...")
    
    app = QApplication.instance()
    if not app:
        app = QApplication(sys.argv)
    
    # åˆ›å»ºAIåŠ©æ‰‹é¢æ¿
    main_window = QMainWindow()
    ai_panel = AIAssistantPanel(main_window)
    
    # æ‰§è¡Œç¡¬ä»¶æ£€æµ‹
    ai_panel.detect_hardware_info()
    
    # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
    print("\nğŸ“Š ç¡¬ä»¶æ£€æµ‹ç»“æœ:")
    print("=" * 40)
    
    hardware_info = ai_panel.hardware_info
    
    print(f"ğŸ–¥ï¸  ç³»ç»Ÿ: {hardware_info.get('system', 'Unknown')}")
    print(f"ğŸ Python: {hardware_info.get('python_version', 'Unknown')}")
    print(f"ğŸ”¥ PyTorch: {hardware_info.get('pytorch_version', 'Unknown')}")
    
    if hardware_info['gpu_available']:
        print(f"âœ… GPU: {hardware_info['gpu_name']}")
        print(f"âœ… CUDA: {hardware_info['cuda_version']}")
        print(f"ğŸ¯ æ¨èè®¾å¤‡: {hardware_info['recommended_device'].upper()}")
    else:
        print("âŒ GPU: æœªæ£€æµ‹åˆ°å¯ç”¨GPU")
        print(f"ğŸ¯ æ¨èè®¾å¤‡: {hardware_info['recommended_device'].upper()}")
    
    # æ˜¾ç¤ºå®‰è£…å‘½ä»¤
    install_cmd = ai_panel.get_pytorch_install_command()
    print(f"\nğŸ“¦ æ¨èå®‰è£…å‘½ä»¤:")
    print(f"   {install_cmd}")
    
    return ai_panel


def run_gpu_cpu_gui_test():
    """è¿è¡ŒGPU/CPUè®­ç»ƒGUIæµ‹è¯•"""
    print("\nğŸ–¥ï¸ è¿è¡ŒGPU/CPUè®­ç»ƒGUIæµ‹è¯•...")
    
    app = QApplication.instance()
    if not app:
        app = QApplication(sys.argv)
    
    # åˆ›å»ºä¸»çª—å£
    main_window = QMainWindow()
    main_window.setWindowTitle("GPU/CPUè®­ç»ƒåŠŸèƒ½æµ‹è¯•")
    main_window.resize(400, 800)
    
    # åˆ›å»ºAIåŠ©æ‰‹é¢æ¿
    ai_panel = AIAssistantPanel(main_window)
    main_window.setCentralWidget(ai_panel)
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®ï¼ˆå……è¶³çš„æ•°æ®ä»¥å¯ç”¨è®­ç»ƒï¼‰
    main_window.label_hist = ['cat', 'dog', 'bird', 'car', 'person']
    
    def mock_update_training_data_stats():
        try:
            user_classes = main_window.label_hist
            estimated_images = len(user_classes) * 25  # æ¯ç±»25å¼ å›¾
            
            ai_panel.training_data_stats.update({
                'total_images': estimated_images,
                'total_annotations': estimated_images * 2,
                'classes_count': len(user_classes)
            })
            
            ai_panel.training_data_count.setText(f"{estimated_images} å¼ ")
            ai_panel.training_data_count.setStyleSheet("color: #27ae60; font-weight: bold; font-size: 11px;")
        except Exception as e:
            print(f"Mock update failed: {e}")
    
    ai_panel.update_training_data_stats = mock_update_training_data_stats
    
    # åˆ·æ–°ä¿¡æ¯
    ai_panel.refresh_training_info()
    
    # æ˜¾ç¤ºçª—å£
    main_window.show()
    
    print("âœ… GPU/CPUè®­ç»ƒåŠŸèƒ½GUIæµ‹è¯•çª—å£å·²æ˜¾ç¤º")
    print("ğŸ“ GPU/CPUè®­ç»ƒåŠŸèƒ½ç‰¹æ€§:")
    print("   - è‡ªåŠ¨æ£€æµ‹GPUå’ŒCUDAç¯å¢ƒ")
    print("   - æ™ºèƒ½æ¨èè®­ç»ƒè®¾å¤‡ï¼ˆGPU/CPUï¼‰")
    print("   - æ˜¾ç¤ºç¡¬ä»¶ä¿¡æ¯å’ŒçŠ¶æ€")
    print("   - ç‚¹å‡»'ğŸš€ å¼€å§‹è®­ç»ƒ'æŸ¥çœ‹è®¾å¤‡é€‰æ‹©")
    print("   - ç‚¹å‡»'âš™ï¸ é…ç½®'ä¸­çš„'ğŸ” æ£€æŸ¥ç¯å¢ƒ'æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š")
    print("   - ç‚¹å‡»'ğŸ“¦ å®‰è£…PyTorch'è·å–å®‰è£…æŒ‡å¯¼")
    
    return main_window


def analyze_gpu_cpu_design():
    """åˆ†æGPU/CPUè®­ç»ƒè®¾è®¡"""
    print("\nğŸ“Š GPU/CPUè®­ç»ƒåŠŸèƒ½è®¾è®¡åˆ†æ:")
    print("=" * 50)
    
    print("ğŸ¯ è®¾è®¡ç›®æ ‡:")
    print("   - è‡ªåŠ¨æ£€æµ‹ç”¨æˆ·ç¡¬ä»¶ç¯å¢ƒ")
    print("   - æ™ºèƒ½æ¨èæœ€ä½³è®­ç»ƒè®¾å¤‡")
    print("   - ç®€åŒ–PyTorchç¯å¢ƒé…ç½®")
    print("   - æä¾›æ¸…æ™°çš„æ€§èƒ½é¢„æœŸ")
    
    print("\nğŸ” ç¡¬ä»¶æ£€æµ‹ç­–ç•¥:")
    print("   - PyTorch CUDAå¯ç”¨æ€§æ£€æµ‹")
    print("   - GPUå‹å·å’ŒCUDAç‰ˆæœ¬è¯†åˆ«")
    print("   - NVIDIAé©±åŠ¨ç¨‹åºæ£€æµ‹")
    print("   - ç³»ç»Ÿå¹³å°å…¼å®¹æ€§æ£€æŸ¥")
    
    print("\nâš™ï¸ ç¯å¢ƒé…ç½®åŠŸèƒ½:")
    print("   - æ ¹æ®ç¡¬ä»¶ç”Ÿæˆå®‰è£…å‘½ä»¤")
    print("   - æ”¯æŒGPUå’ŒCPUç‰ˆæœ¬é€‰æ‹©")
    print("   - æä¾›è¯¦ç»†çš„å®‰è£…æŒ‡å¯¼")
    print("   - ç¯å¢ƒæ£€æŸ¥å’ŒéªŒè¯å·¥å…·")
    
    print("\nğŸ¨ ç”¨æˆ·ä½“éªŒè®¾è®¡:")
    print("   - è®¾å¤‡çŠ¶æ€å®æ—¶æ˜¾ç¤º")
    print("   - æ™ºèƒ½è®¾å¤‡æ¨è")
    print("   - ä¸€é”®ç¯å¢ƒæ£€æŸ¥")
    print("   - å‚»ç“œå¼å®‰è£…æŒ‡å¯¼")
    
    print("\nğŸš€ æ€§èƒ½ä¼˜åŒ–:")
    print("   - GPUè®­ç»ƒ: é€Ÿåº¦å¿«ï¼Œé€‚åˆå¤§æ•°æ®é›†")
    print("   - CPUè®­ç»ƒ: å…¼å®¹æ€§å¥½ï¼Œé€‚åˆå°æ•°æ®é›†")
    print("   - è‡ªåŠ¨è®¾å¤‡å›é€€æœºåˆ¶")
    print("   - è®­ç»ƒå‚æ•°æ™ºèƒ½è°ƒæ•´")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª GPU/CPUè®­ç»ƒåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡Œç¡¬ä»¶æ£€æµ‹æµ‹è¯•
    ai_panel = run_hardware_detection_test()
    
    # è¿è¡Œå•å…ƒæµ‹è¯•
    print("\nğŸ“‹ è¿è¡Œå•å…ƒæµ‹è¯•...")
    unittest.main(argv=[''], exit=False, verbosity=2)
    
    # æ˜¾ç¤ºè®¾è®¡åˆ†æ
    analyze_gpu_cpu_design()
    
    # è¿è¡ŒGUIæµ‹è¯•
    if len(sys.argv) > 1 and sys.argv[1] == '--gui':
        window = run_gpu_cpu_gui_test()
        
        # ä¿æŒçª—å£æ‰“å¼€
        app = QApplication.instance()
        if app:
            sys.exit(app.exec_())


if __name__ == '__main__':
    main()
