#!/usr/bin/env python3
"""
æ¨¡æ‹ŸåŸå§‹CUDAé”™è¯¯å¹¶æµ‹è¯•ä¿®å¤æ•ˆæœ
"""

import sys
import os
import tempfile
import unittest.mock as mock

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def simulate_torchvision_nms_cuda_error():
    """æ¨¡æ‹Ÿtorchvision::nms CUDAé”™è¯¯"""
    error_message = """
Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMeta, Tracer, AutocastCPU, AutocastMTIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].
"""
    return RuntimeError(error_message.strip())

def test_cuda_error_handling():
    """æµ‹è¯•CUDAé”™è¯¯å¤„ç†"""
    print("ğŸ” æµ‹è¯•CUDAé”™è¯¯å¤„ç†æœºåˆ¶...")
    
    try:
        from libs.ai_assistant.yolo_predictor import YOLOPredictor
        from ultralytics import YOLO
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = create_test_image()
        if not test_image:
            print("âŒ æ— æ³•åˆ›å»ºæµ‹è¯•å›¾åƒ")
            return False
        
        print(f"  æµ‹è¯•å›¾åƒ: {test_image}")
        
        # åˆ›å»ºé¢„æµ‹å™¨
        predictor = YOLOPredictor()
        
        # åŠ è½½æ¨¡å‹
        if not predictor.load_model('yolov8n.pt'):
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
            return False
        
        print(f"  æ¨¡å‹åŠ è½½æˆåŠŸï¼Œå½“å‰è®¾å¤‡: {predictor.device}")
        
        # æ¨¡æ‹ŸCUDAé”™è¯¯ - ä¿®æ”¹æ¨¡å‹çš„__call__æ–¹æ³•
        original_call = predictor.model.__call__
        
        def mock_model_call(*args, **kwargs):
            # ç¬¬ä¸€æ¬¡è°ƒç”¨æŠ›å‡ºCUDAé”™è¯¯
            if not hasattr(mock_model_call, 'called'):
                mock_model_call.called = True
                raise simulate_torchvision_nms_cuda_error()
            else:
                # ç¬¬äºŒæ¬¡è°ƒç”¨ä½¿ç”¨åŸå§‹æ–¹æ³•ï¼ˆæ¨¡æ‹ŸCPUæ¨¡å¼æˆåŠŸï¼‰
                return original_call(*args, **kwargs)
        
        # æ›¿æ¢æ¨¡å‹è°ƒç”¨æ–¹æ³•
        predictor.model.__call__ = mock_model_call
        
        print("  æ¨¡æ‹ŸCUDAé”™è¯¯å¹¶æ‰§è¡Œé¢„æµ‹...")
        
        # æ‰§è¡Œé¢„æµ‹ - åº”è¯¥è‡ªåŠ¨å›é€€åˆ°CPU
        result = predictor.predict_single(test_image, conf_threshold=0.25)
        
        if result:
            print(f"  âœ… é¢„æµ‹æˆåŠŸï¼ˆç»è¿‡CUDAå›é€€ï¼‰ï¼Œè®¾å¤‡: {predictor.device}")
            print(f"  æ£€æµ‹åˆ° {len(result.detections)} ä¸ªç›®æ ‡")
            print(f"  æ¨ç†æ—¶é—´: {result.inference_time:.3f}ç§’")
            
            # éªŒè¯è®¾å¤‡å·²åˆ‡æ¢åˆ°CPU
            if predictor.device == "cpu":
                print("  âœ… æˆåŠŸå›é€€åˆ°CPUæ¨¡å¼")
                success = True
            else:
                print(f"  âŒ è®¾å¤‡æœªæ­£ç¡®åˆ‡æ¢ï¼Œå½“å‰: {predictor.device}")
                success = False
        else:
            print("  âŒ é¢„æµ‹å¤±è´¥")
            success = False
        
        # æ¢å¤åŸå§‹æ–¹æ³•
        predictor.model.__call__ = original_call
        
        # æ¸…ç†æµ‹è¯•å›¾åƒ
        if test_image and os.path.exists(test_image):
            os.unlink(test_image)
        
        return success
        
    except Exception as e:
        print(f"âŒ CUDAé”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_test_image():
    """åˆ›å»ºä¸€ä¸ªæµ‹è¯•å›¾åƒ"""
    try:
        from PIL import Image
        import numpy as np
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾åƒ
        img_array = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        img = Image.fromarray(img_array)
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(suffix='.jpg', delete=False)
        img.save(temp_file.name)
        temp_file.close()
        
        return temp_file.name
        
    except ImportError:
        print("âš ï¸ PILæœªå®‰è£…ï¼Œä½¿ç”¨ç°æœ‰æµ‹è¯•å›¾åƒ")
        # æŸ¥æ‰¾ç°æœ‰çš„æµ‹è¯•å›¾åƒ
        test_dirs = ['test_images', 'examples', 'data']
        for test_dir in test_dirs:
            if os.path.exists(test_dir):
                for file in os.listdir(test_dir):
                    if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                        return os.path.join(test_dir, file)
        
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒ")
        return None

def test_ai_assistant_panel_integration():
    """æµ‹è¯•AIåŠ©æ‰‹é¢æ¿é›†æˆ"""
    print("\nğŸ” æµ‹è¯•AIåŠ©æ‰‹é¢æ¿é›†æˆ...")
    
    try:
        # è¿™é‡Œåªæµ‹è¯•å¯¼å…¥å’ŒåŸºæœ¬åŠŸèƒ½ï¼Œä¸å¯åŠ¨GUI
        from libs.ai_assistant_panel import AIAssistantPanel
        
        print("  âœ… AIåŠ©æ‰‹é¢æ¿å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•æ˜¯å¦æœ‰å¼ºåˆ¶CPUé€‰é¡¹ç›¸å…³çš„æ–¹æ³•
        panel_methods = dir(AIAssistantPanel)
        
        if 'on_force_cpu_changed' in panel_methods:
            print("  âœ… å¼ºåˆ¶CPUæ¨¡å¼å›è°ƒæ–¹æ³•å­˜åœ¨")
        else:
            print("  âŒ å¼ºåˆ¶CPUæ¨¡å¼å›è°ƒæ–¹æ³•ç¼ºå¤±")
            return False
        
        print("  âœ… AIåŠ©æ‰‹é¢æ¿é›†æˆæµ‹è¯•é€šè¿‡")
        return True
        
    except ImportError as e:
        print(f"âŒ AIåŠ©æ‰‹é¢æ¿å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ AIåŠ©æ‰‹é¢æ¿æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("CUDAé”™è¯¯æ¨¡æ‹Ÿå’Œä¿®å¤éªŒè¯æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•1: CUDAé”™è¯¯å¤„ç†
    cuda_error_ok = test_cuda_error_handling()
    
    # æµ‹è¯•2: AIåŠ©æ‰‹é¢æ¿é›†æˆ
    panel_ok = test_ai_assistant_panel_integration()
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"CUDAé”™è¯¯å¤„ç†: {'âœ…' if cuda_error_ok else 'âŒ'}")
    print(f"é¢æ¿é›†æˆæµ‹è¯•: {'âœ…' if panel_ok else 'âŒ'}")
    
    if cuda_error_ok and panel_ok:
        print("\nğŸ‰ ä¿®å¤éªŒè¯æˆåŠŸï¼")
        print("âœ… CUDAé”™è¯¯ä¼šè¢«è‡ªåŠ¨æ•è·å¹¶å›é€€åˆ°CPUæ¨¡å¼")
        print("âœ… AIåŠ©æ‰‹é¢æ¿æ”¯æŒå¼ºåˆ¶CPUæ¨¡å¼é€‰é¡¹")
        print("âœ… ç”¨æˆ·å¯ä»¥ç»§ç»­æ­£å¸¸ä½¿ç”¨é¢„æµ‹åŠŸèƒ½")
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("   - å¦‚æœé‡åˆ°CUDAç›¸å…³é”™è¯¯ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å›é€€åˆ°CPU")
        print("   - å¯ä»¥åœ¨AIåŠ©æ‰‹é¢æ¿ä¸­å‹¾é€‰'å¼ºåˆ¶ä½¿ç”¨CPUæ¨¡å¼'é¿å…CUDAé—®é¢˜")
        print("   - CPUæ¨¡å¼è™½ç„¶è¾ƒæ…¢ï¼Œä½†ç¡®ä¿åŠŸèƒ½ç¨³å®šå¯ç”¨")
    else:
        print("\nâš ï¸ ä¿®å¤éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
    
    return cuda_error_ok and panel_ok

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
